{
    "root": {
        "data": {
            "id": "cl622e7hj940",
            "created": 1656854962964,
            "text": "存储器级别",
            "image": "",
            "imageTitle": "",
            "imageSize": "",
            "background": "#73a1bf",
            "note": "总结\n各种存储器之间的关系，可以用我们在图书馆学习这个场景来理解。\n\nCPU 可以比喻成我们的大脑，我们当前正在思考和处理的知识的过程，就好比 CPU 中的寄存器处理数据的过程，速度极快，但是容量很小。而 CPU 中的 L1-L3 Cache 好比我们大脑中的短期记忆和长期记忆，需要小小花费点时间来调取数据并处理。\n\n我们面前的桌子就相当于内存，能放下更多的书（数据），但是找起来和看起来就要花费一些时间，相比 CPU Cache 慢不少。而图书馆的书架相当于硬盘，能放下比内存更多的数据，但找起来就更费时间了，可以说是最慢的存储器设备了。\n\n从 寄存器、CPU Cache，到内存、硬盘，这样一层层下来的存储器，访问速度越来越慢，存储容量越来越大，价格也越来越便宜，而且每个存储器只和相邻的一层存储器设备打交道，于是这样就形成了存储器的层次结构。\n\n再来回答，开头的问题：那机械硬盘、固态硬盘、内存这三个存储器，到底和 CPU L1 Cache 相比速度差多少倍呢？\n\nCPU L1 Cache 随机访问延时是 1 纳秒，内存则是 100 纳秒，所以 CPU L1 Cache 比内存快 100 倍左右。\n\nSSD 随机访问延时是 150 微秒，所以 CPU L1 Cache 比 SSD 快 150000 倍左右。\n\n最慢的机械硬盘随机访问延时已经高达 10 毫秒，我们来看看机械硬盘到底有多「龟速」：\n\nSSD 比机械硬盘快 70 倍左右；\n内存比机械硬盘快 100000 倍左右；\nCPU L1 Cache 比机械硬盘快 10000000 倍左右；\n我们把上述的时间比例差异放大后，就能非常直观感受到它们的性能差异了。如果 CPU 访问 L1 Cache 的缓存时间是 1 秒，那访问内存则需要大约 2 分钟，随机访问 SSD 里的数据则需要 1.7 天，访问机械硬盘那更久，长达近 4 个月。\n\n可以发现，不同的存储器之间性能差距很大，构造存储器分级很有意义，分级的目的是要构造缓存体系"
        },
        "children": [
            {
                "data": {
                    "id": "cl624v3albk0",
                    "created": 1656855156444,
                    "text": "寄存器",
                    "expandState": "expand",
                    "layout_right_offset": {
                        "x": -11.333333333333258,
                        "y": -10.666666666666686
                    }
                },
                "children": [
                    {
                        "data": {
                            "id": "cl6255tmcg00",
                            "created": 1656855179804,
                            "text": "访问速度"
                        },
                        "children": []
                    },
                    {
                        "data": {
                            "id": "cl625e31ka80",
                            "created": 1656855197788,
                            "text": "可存储大小"
                        },
                        "children": []
                    }
                ]
            },
            {
                "data": {
                    "id": "cl626hsqytk0",
                    "created": 1656855284236,
                    "text": "CPU Cache",
                    "layout_mind_offset": {
                        "x": 449.1666488183878,
                        "y": 110.83332892921254
                    },
                    "expandState": "expand",
                    "layout_right_offset": {
                        "x": 8,
                        "y": 6.666666666666629
                    },
                    "note": "由于随着计算机技术的发展，CPU 与 内存的访问速度相差越来越多，如今差距已经高达好几百倍了，所以 CPU 内部嵌入了 CPU Cache 组件，作为内存与 CPU 之间的缓存层，CPU Cache 由于离 CPU 核心很近，所以访问速度也是非常快的，但由于所需材料成本比较高，它不像内存动辄几个 GB 大小，而是仅有几十 KB 到 MB 大小。\n\n当 CPU 访问数据的时候，先是访问 CPU Cache，如果缓存命中的话，则直接返回数据，就不用每次都从内存读取速度了。因此，缓存命中率越高，代码的性能越好。\n\n但需要注意的是，当 CPU 访问数据时，如果 CPU Cache 没有缓存该数据，则会从内存读取数据，但是并不是只读一个数据，而是一次性读取一块一块的数据存放到 CPU Cache 中，之后才会被 CPU 读取。\n\n内存地址映射到 CPU Cache 地址里的策略有很多种，其中比较简单是直接映射 Cache，它巧妙的把内存地址拆分成「索引 + 组标记 + 偏移量」的方式，使得我们可以将很大的内存地址，映射到很小的 CPU Cache 地址里。\n\n要想写出让 CPU 跑得更快的代码，就需要写出缓存命中率高的代码，CPU L1 Cache 分为数据缓存和指令缓存，因而需要分别提高它们的缓存命中率：\n\n对于数据缓存，我们在遍历数据的时候，应该按照内存布局的顺序操作，这是因为 CPU Cache 是根据 CPU Cache Line 批量操作数据的，所以顺序地操作连续内存数据时，性能能得到有效的提升；\n对于指令缓存，有规律的条件分支语句能够让 CPU 的分支预测器发挥作用，进一步提高执行的效率；\n另外，对于多核 CPU 系统，线程可能在不同 CPU 核心来回切换，这样各个核心的缓存命中率就会受到影响，于是要想提高线程的缓存命中率，可以考虑把线程绑定 CPU 到某一个 CPU 核心。\n\n#"
                },
                "children": [
                    {
                        "data": {
                            "id": "cl6282r2vvs0",
                            "created": 1656855408212,
                            "text": "访问速度",
                            "note": "树组中元素占据内存是连续的\n\n所以不连续性、跳跃式访问数据元素的方式，可能不能充分利用到了 CPU Cache 的特性，从而代码的性能不高！"
                        },
                        "children": []
                    },
                    {
                        "data": {
                            "id": "cl628fnarmo0",
                            "created": 1656855436282,
                            "text": "三层缓存"
                        },
                        "children": []
                    },
                    {
                        "data": {
                            "id": "cl88v345bk00",
                            "created": 1657077257951,
                            "text": "读取数据的过程是怎样的",
                            "note": "理解 CPU 是如何读写数据的前提，是要理解 CPU 的架构，CPU 内部的多个 Cache + 外部的内存和磁盘都就构成了金字塔的存储器结构，在这个金字塔中，越往下，存储器的容量就越大，但访问速度就会小。\n\nCPU 读写数据的时候，并不是按一个一个字节为单位来进行读写，而是以 CPU Line 大小为单位，CPU Line 大小一般是 64 个字节，也就意味着 CPU 读写数据的时候，每一次都是以 64 字节大小为一块进行操作。\n\n因此，如果我们操作的数据是数组，那么访问数组元素的时候，按内存分布的地址顺序进行访问，这样能充分利用到 Cache，程序的性能得到提升。但如果操作的数据不是数组，而是普通的变量，并在多核 CPU 的情况下，我们还需要避免 Cache Line 伪共享的问题。\n\n所谓的 Cache Line 伪共享问题就是，多个线程同时读写同一个 Cache Line 的不同变量时，而导致 CPU Cache 失效的现象。那么对于多个线程共享的热点数据，即经常会修改的数据，应该避免这些数据刚好在同一个 Cache Line 中，避免的方式一般有 Cache Line 大小字节对齐，以及字节填充等方法。\n\n系统中需要运行的多线程数一般都会大于 CPU 核心，这样就会导致线程排队等待 CPU，这可能会产生一定的延时，如果我们的任务对延时容忍度很低，则可以通过一些人为手段干预 Linux 的默认调度策略和优先级。\n\n#"
                        },
                        "children": []
                    }
                ]
            },
            {
                "data": {
                    "id": "cl628ot02v40",
                    "created": 1656855456218,
                    "text": "内存"
                },
                "children": [
                    {
                        "data": {
                            "id": "cl628vm6bso0",
                            "created": 1656855471042,
                            "text": "芯片：DRAM"
                        },
                        "children": []
                    },
                    {
                        "data": {
                            "id": "cl6296mfbyo0",
                            "created": 1656855495002,
                            "text": "访问速度"
                        },
                        "children": []
                    }
                ]
            },
            {
                "data": {
                    "id": "cl62aax5m5c0",
                    "created": 1656855582722,
                    "text": "硬盘"
                },
                "children": [
                    {
                        "data": {
                            "id": "cl62arzu91c0",
                            "created": 1656855619890,
                            "text": "SSD"
                        },
                        "children": []
                    },
                    {
                        "data": {
                            "id": "cl62aus03eo0",
                            "created": 1656855625946,
                            "text": "HHD"
                        },
                        "children": []
                    }
                ]
            }
        ]
    },
    "template": "right",
    "theme": "fresh-blue",
    "version": "1.4.43"
}